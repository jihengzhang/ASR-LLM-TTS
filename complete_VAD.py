#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´ç‰ˆ FunASR VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ
é›†æˆ FunASR VAD æ¨¡å‹å’Œå†…ç½®ç®—æ³•
"""

import os
import time
import wave
import numpy as np
import threading
from datetime import datetime
import colorama
from colorama import Fore, Style

# åˆå§‹åŒ– colorama
colorama.init()

try:
    import pyaudio
    print(f"{Fore.GREEN}âœ“ PyAudio æ¨¡å—å·²åŠ è½½{Style.RESET_ALL}")
except ImportError:
    print(f"{Fore.RED}âœ— PyAudio æœªå®‰è£…{Style.RESET_ALL}")
    exit(1)

try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    print(f"{Fore.GREEN}âœ“ FunASR æ¨¡å—å·²åŠ è½½{Style.RESET_ALL}")
except ImportError:
    FUNASR_AVAILABLE = False
    print(f"{Fore.YELLOW}âš  FunASR æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨å†…ç½® VAD{Style.RESET_ALL}")

# é…ç½®å‚æ•°
RATE = 16000
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1

# VAD å‚æ•°
ENERGY_THRESHOLD = 0.01
ZCR_THRESHOLD = 0.1
MIN_SPEECH_DURATION = 1.0
SILENCE_DURATION = 2.0

class HybridVAD:
    """æ··åˆ VAD ç³»ç»Ÿï¼šFunASR + å†…ç½®ç®—æ³•"""
    
    def __init__(self):
        self.energy_history = []
        self.background_energy = 0.001
        self.funasr_vad = None
        self.audio_buffer = []
        self.buffer_size = RATE * 2  # 2ç§’ç¼“å†²
        
        # åˆå§‹åŒ– FunASR VAD
        if FUNASR_AVAILABLE:
            self.init_funasr()
    
    def init_funasr(self):
        """åˆå§‹åŒ– FunASR VAD æ¨¡å‹"""
        try:
            print(f"{Fore.YELLOW}æ­£åœ¨åŠ è½½ FunASR VAD æ¨¡å‹...{Style.RESET_ALL}")
            
            # è®¾ç½®æ¨¡å‹ç¼“å­˜åˆ°å½“å‰ç›®å½•
            current_dir = os.getcwd()
            os.environ['MODELSCOPE_CACHE'] = current_dir
            os.environ['HF_HOME'] = current_dir
            
            # åŠ è½½æ¨¡å‹ï¼Œä½†ä¸åœ¨è¿™é‡Œè¾“å‡ºè¿›åº¦æ¡
            self.funasr_vad = AutoModel(
                model="damo/speech_fsmn_vad_zh-cn-16k-common-pytorch",
                model_revision="v2.0.4"
            )
            print(f"{Fore.GREEN}âœ“ FunASR VAD æ¨¡å‹åŠ è½½æˆåŠŸ{Style.RESET_ALL}")
            
        except Exception as e:
            print(f"{Fore.RED}âœ— FunASR VAD åŠ è½½å¤±è´¥: {e}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}å°†ä½¿ç”¨å†…ç½® VAD ç®—æ³•{Style.RESET_ALL}")
            self.funasr_vad = None
    
    def calculate_features(self, frame):
        """è®¡ç®—éŸ³é¢‘ç‰¹å¾"""
        if len(frame) == 0:
            return {'energy': 0, 'zcr': 0}
            
        # å½’ä¸€åŒ–
        frame = frame.astype(np.float32) / 32768.0
        
        # èƒ½é‡
        energy = np.mean(frame ** 2)
        
        # è¿‡é›¶ç‡
        zcr = np.mean(0.5 * np.abs(np.diff(np.sign(frame))))
        
        return {'energy': energy, 'zcr': zcr}
    
    def update_background(self, energy):
        """æ›´æ–°èƒŒæ™¯å™ªå£°"""
        self.energy_history.append(energy)
        if len(self.energy_history) > 50:
            self.energy_history.pop(0)
        
        if len(self.energy_history) >= 10:
            self.background_energy = np.percentile(self.energy_history, 20)
    
    def builtin_vad(self, frame):
        """å†…ç½® VAD ç®—æ³•"""
        features = self.calculate_features(frame)
        energy = features['energy']
        zcr = features['zcr']
        
        # æ›´æ–°èƒŒæ™¯å™ªå£°
        self.update_background(energy)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        adaptive_threshold = max(self.background_energy * 5, ENERGY_THRESHOLD)
        
        # åˆ¤æ–­è¯­éŸ³
        energy_check = energy > adaptive_threshold
        zcr_check = zcr > ZCR_THRESHOLD
        
        features.update({
            'threshold': adaptive_threshold,
            'background': self.background_energy
        })
        
        return energy_check and zcr_check, features
    
    def funasr_vad_detect(self, audio_array):
        """FunASR VAD æ£€æµ‹"""
        if self.funasr_vad is None:
            return None
            
        try:
            # ç¡®ä¿éŸ³é¢‘é•¿åº¦è¶³å¤Ÿ
            if len(audio_array) < RATE * 0.5:  # è‡³å°‘0.5ç§’
                return None
            
            # FunASR éœ€è¦çš„æ ¼å¼
            result = self.funasr_vad.generate(input=audio_array)
            
            if result and len(result) > 0:
                # è§£æç»“æœ
                vad_result = result[0].get('value', [])
                # å¦‚æœæœ‰è¯­éŸ³æ®µè½ï¼Œè®¤ä¸ºæ£€æµ‹åˆ°è¯­éŸ³
                return len(vad_result) > 0
                
        except Exception as e:
            # é™é»˜å¤„ç† FunASR é”™è¯¯ï¼Œé¿å…å¹²æ‰°æ˜¾ç¤º
            pass
        
        return None
    
    def detect(self, frame):
        """æ··åˆæ£€æµ‹"""
        # å†…ç½®ç®—æ³•
        builtin_result, features = self.builtin_vad(frame)
        
        # æ›´æ–°éŸ³é¢‘ç¼“å†²åŒº
        audio_array = frame.astype(np.float32) / 32768.0
        self.audio_buffer.extend(audio_array)
        
        # ä¿æŒç¼“å†²åŒºå¤§å°
        if len(self.audio_buffer) > self.buffer_size:
            self.audio_buffer = self.audio_buffer[-self.buffer_size:]
        
        # FunASR æ£€æµ‹ï¼ˆæ¯éš”ä¸€æ®µæ—¶é—´æ£€æµ‹ä¸€æ¬¡ï¼‰
        funasr_result = None
        if len(self.audio_buffer) >= RATE and len(self.audio_buffer) % (RATE // 2) == 0:
            # æ¯0.5ç§’æ£€æµ‹ä¸€æ¬¡
            funasr_result = self.funasr_vad_detect(np.array(self.audio_buffer))
        
        # ç»¼åˆç»“æœ
        if funasr_result is not None:
            final_result = funasr_result
            method = "FunASR"
        else:
            final_result = builtin_result  
            method = "å†…ç½®"
        
        features['method'] = method
        features['funasr'] = funasr_result
        features['builtin'] = builtin_result
        
        return final_result, features

class VADRecorder:
    """VAD å½•éŸ³å™¨"""
    
    def __init__(self):
        print(f"\n{Fore.CYAN}{Style.BRIGHT}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{Style.BRIGHT}        å®Œæ•´ç‰ˆ FunASR VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{Style.BRIGHT}{'='*60}{Style.RESET_ALL}\n")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.audio = pyaudio.PyAudio()
        self.vad = HybridVAD()
        
        # æ£€æŸ¥è®¾å¤‡
        self.check_audio_devices()
        
        # å½•éŸ³çŠ¶æ€
        self.is_recording = False
        self.frames = []
        self.stop_flag = False
        
        # è¯­éŸ³çŠ¶æ€
        self.speech_active = False
        self.speech_start_time = None
        self.silence_start_time = None
        
        # è¾“å‡ºç›®å½•
        self.output_dir = "recordings"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"{Fore.GREEN}âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}VAD æ¨¡å¼: {'FunASR + å†…ç½®ç®—æ³•' if FUNASR_AVAILABLE and self.vad.funasr_vad else 'å†…ç½®ç®—æ³•'}{Style.RESET_ALL}\n")
    
    def check_audio_devices(self):
        """æ£€æŸ¥éŸ³é¢‘è®¾å¤‡"""
        device_count = self.audio.get_device_count()
        print(f"{Fore.BLUE}éŸ³é¢‘è®¾å¤‡æ£€æµ‹:{Style.RESET_ALL}")
        
        input_count = 0
        for i in range(device_count):
            info = self.audio.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                input_count += 1
                if input_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªè®¾å¤‡
                    print(f"  [{i}] {info['name']}")
        
        if input_count > 3:
            print(f"  ... è¿˜æœ‰ {input_count - 3} ä¸ªè®¾å¤‡")
        
        if input_count == 0:
            raise Exception("æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡")
        
        print(f"{Fore.GREEN}âœ“ æ‰¾åˆ° {input_count} ä¸ªè¾“å…¥è®¾å¤‡{Style.RESET_ALL}")
    
    def display_status(self, is_speech, features):
        """æ˜¾ç¤ºå®æ—¶çŠ¶æ€"""
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        if is_speech:
            indicator = f"{Fore.GREEN}ğŸ¤ è¯­éŸ³{Style.RESET_ALL}"
        else:
            indicator = f"{Fore.BLUE}ğŸ”‡ é™éŸ³{Style.RESET_ALL}"
        
        # æ£€æµ‹æ–¹æ³•
        method = features.get('method', 'æœªçŸ¥')
        method_color = Fore.CYAN if method == "FunASR" else Fore.YELLOW
        
        # çŠ¶æ€è¡Œ
        status_line = (
            f"\r{indicator} | "
            f"{method_color}{method}{Style.RESET_ALL} | "
            f"èƒ½é‡: {features.get('energy', 0):.4f} | "
            f"è¿‡é›¶ç‡: {features.get('zcr', 0):.3f} | "
            f"é˜ˆå€¼: {features.get('threshold', 0):.4f}"
        )
        
        # å¦‚æœæœ‰ FunASR ç»“æœï¼Œæ˜¾ç¤ºå¯¹æ¯”
        if features.get('funasr') is not None:
            builtin = "âˆš" if features.get('builtin') else "Ã—"
            funasr = "âˆš" if features.get('funasr') else "Ã—"
            status_line += f" | å†…ç½®:{builtin} FunASR:{funasr}"
        
        print(status_line + " " * 10, end='')
    
    def start_stream(self):
        """å¼€å§‹éŸ³é¢‘æµ"""
        print(f"{Fore.YELLOW}å¼€å§‹è¯­éŸ³ç›‘å¬... æŒ‰ Ctrl+C åœæ­¢{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        
        try:
            stream = self.audio.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK
            )
            
            stream.start_stream()
            
            while not self.stop_flag:
                if stream.is_active():
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    self.process_audio(data)
                else:
                    time.sleep(0.01)
                    
        except Exception as e:
            print(f"\n{Fore.RED}éŸ³é¢‘æµé”™è¯¯: {e}{Style.RESET_ALL}")
        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}ç”¨æˆ·åœæ­¢ç¨‹åº{Style.RESET_ALL}")
        finally:
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass
            self.audio.terminate()
            
            if self.is_recording:
                self.stop_recording()
    
    def process_audio(self, data):
        """å¤„ç†éŸ³é¢‘æ•°æ®"""
        # è½¬æ¢éŸ³é¢‘
        audio_array = np.frombuffer(data, dtype=np.int16)
        
        # VAD æ£€æµ‹
        is_speech, features = self.vad.detect(audio_array)
        
        # æ˜¾ç¤ºçŠ¶æ€
        self.display_status(is_speech, features)
        
        # è¯­éŸ³çŠ¶æ€æœº
        current_time = time.time()
        
        if is_speech:
            if not self.speech_active:
                # è¯­éŸ³å¼€å§‹
                self.speech_active = True
                self.speech_start_time = current_time
                self.silence_start_time = None
                print(f"\n{Fore.YELLOW}ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ ({features.get('method', 'æœªçŸ¥')}){Style.RESET_ALL}")
        else:
            if self.speech_active:
                if self.silence_start_time is None:
                    self.silence_start_time = current_time
                
                # æ£€æŸ¥é™éŸ³æ—¶é•¿
                silence_duration = current_time - self.silence_start_time
                if silence_duration >= SILENCE_DURATION:
                    # è¯­éŸ³ç»“æŸ
                    speech_duration = current_time - self.speech_start_time
                    print(f"\n{Fore.CYAN}ğŸ”‡ è¯­éŸ³ç»“æŸï¼ŒæŒç»­ {speech_duration:.2f} ç§’{Style.RESET_ALL}")
                    
                    if speech_duration >= MIN_SPEECH_DURATION:
                        if not self.is_recording:
                            print(f"{Fore.GREEN}âœ“ å¼€å§‹å½•éŸ³{Style.RESET_ALL}")
                            self.start_recording()
                        else:
                            print(f"{Fore.CYAN}âœ“ åœæ­¢å½•éŸ³{Style.RESET_ALL}")
                            self.stop_recording()
                    else:
                        print(f"{Fore.RED}âœ— è¯­éŸ³å¤ªçŸ­ï¼Œå¿½ç•¥ ({speech_duration:.2f}s){Style.RESET_ALL}")
                    
                    self.speech_active = False
                    self.speech_start_time = None
                    self.silence_start_time = None
        
        # å½•éŸ³ä¸­ä¿å­˜æ•°æ®
        if self.is_recording:
            self.frames.append(data)
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        self.is_recording = True
        self.frames = []
        print(f"{Fore.GREEN}ğŸ”´ å¼€å§‹å½•éŸ³...{Style.RESET_ALL}")
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if self.is_recording and len(self.frames) > 0:
            self.is_recording = False
            
            # ä¿å­˜æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.output_dir, f"funasr_vad_{timestamp}.wav")
            
            with wave.open(filename, 'wb') as wf:
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(self.audio.get_sample_size(FORMAT))
                wf.setframerate(RATE)
                wf.writeframes(b''.join(self.frames))
            
            # æ˜¾ç¤ºä¿¡æ¯
            duration = len(self.frames) * CHUNK / RATE
            file_size = os.path.getsize(filename) / 1024
            print(f"{Fore.CYAN}ğŸ“ å½•éŸ³ä¿å­˜: {filename}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ğŸ“Š æ—¶é•¿: {duration:.2f}s, å¤§å°: {file_size:.1f}KB{Style.RESET_ALL}")
            
            self.frames = []

def main():
    """ä¸»å‡½æ•°"""
    print(f"{Fore.CYAN}{Style.BRIGHT}FunASR VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}åŠŸèƒ½: å®æ—¶è¯­éŸ³æ£€æµ‹ + è‡ªåŠ¨å½•éŸ³{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}é…ç½®: æœ€å°è¯­éŸ³ {MIN_SPEECH_DURATION}s, é™éŸ³è¶…æ—¶ {SILENCE_DURATION}s{Style.RESET_ALL}")
    
    try:
        recorder = VADRecorder()
        recorder.start_stream()
    except Exception as e:
        print(f"\n{Fore.RED}ç³»ç»Ÿé”™è¯¯: {e}{Style.RESET_ALL}")

if __name__ == "__main__":
    main()
