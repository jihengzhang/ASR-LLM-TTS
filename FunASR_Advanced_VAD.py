"""
ç®€åŒ–ç‰ˆ FunASR-style VAD å®ç°
ä½¿ç”¨ numpy å’ŒåŸºæœ¬éŸ³é¢‘å¤„ç†å®ç°è¯­éŸ³æ´»åŠ¨æ£€æµ‹
"""

import os
import time
import wave
import numpy as np
import threading
import queue
from datetime import datetime
import collections
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    print("PyAudio æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install pyaudio")
    PYAUDIO_AVAILABLE = False

if not PYAUDIO_AVAILABLE:
    print("è¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–: pip install pyaudio")
    exit(1)

# é…ç½®å‚æ•°
RATE = 16000  # é‡‡æ ·ç‡
CHUNK = 1024  # æ¯ä¸ªç¼“å†²åŒºçš„å¸§æ•°
FORMAT = pyaudio.paInt16  # éŸ³é¢‘æ ¼å¼
CHANNELS = 1  # å£°é“æ•°
KEYWORD = "ä½ å¥½"  # æ¿€æ´»å…³é”®è¯

# æ”¹è¿›çš„ VAD å‚æ•°
SILENCE_THRESHOLD = 800  # é™éŸ³é˜ˆå€¼
ACTIVITY_THRESHOLD = 1200  # è¯­éŸ³æ´»åŠ¨é˜ˆå€¼
SILENCE_DURATION = 1.5  # é™éŸ³æŒç»­æ—¶é—´(ç§’)
RECORD_PADDING = 0.8  # å½•éŸ³å‰åé¢å¤–ä¿ç•™çš„ç§’æ•°
MIN_SPEECH_DURATION = 0.3  # æœ€å°è¯­éŸ³æŒç»­æ—¶é—´(ç§’)

# é«˜çº§ VAD å‚æ•°
FRAME_WINDOW = 10  # ç”¨äºå¹³æ»‘çš„å¸§çª—å£å¤§å°
ENERGY_THRESHOLD = 0.1  # èƒ½é‡é˜ˆå€¼
ZERO_CROSSING_THRESHOLD = 0.3  # è¿‡é›¶ç‡é˜ˆå€¼

class AdvancedVAD:
    """æ”¹è¿›çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.frame_buffer = collections.deque(maxlen=FRAME_WINDOW)
        self.energy_buffer = collections.deque(maxlen=FRAME_WINDOW)
        self.zcr_buffer = collections.deque(maxlen=FRAME_WINDOW)
        
    def calculate_energy(self, frame):
        """è®¡ç®—å¸§èƒ½é‡"""
        return np.sum(frame ** 2) / len(frame)
    
    def calculate_zero_crossing_rate(self, frame):
        """è®¡ç®—è¿‡é›¶ç‡"""
        signs = np.sign(frame)
        sign_changes = np.diff(signs)
        return np.sum(np.abs(sign_changes)) / (2 * len(frame))
    
    def is_speech(self, frame):
        """åˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³"""
        # è®¡ç®—åŸºæœ¬ç‰¹å¾
        volume = np.abs(frame).mean()
        energy = self.calculate_energy(frame)
        zcr = self.calculate_zero_crossing_rate(frame)
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.frame_buffer.append(frame)
        self.energy_buffer.append(energy)
        self.zcr_buffer.append(zcr)
        
        # åŸºæœ¬éŸ³é‡æ£€æµ‹
        volume_speech = volume > SILENCE_THRESHOLD
        
        # å¦‚æœç¼“å†²åŒºä¸å¤Ÿå¤§ï¼Œåªä½¿ç”¨éŸ³é‡æ£€æµ‹
        if len(self.energy_buffer) < FRAME_WINDOW:
            return volume_speech, volume
        
        # è®¡ç®—å¹³å‡ç‰¹å¾
        avg_energy = np.mean(self.energy_buffer)
        avg_zcr = np.mean(self.zcr_buffer)
        
        # ç»„åˆåˆ¤æ–­æ¡ä»¶
        energy_speech = avg_energy > ENERGY_THRESHOLD * np.max(self.energy_buffer)
        zcr_speech = avg_zcr > ZERO_CROSSING_THRESHOLD
        
        # ç»¼åˆåˆ¤æ–­ï¼ˆè‡³å°‘æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼‰
        speech_indicators = [volume_speech, energy_speech, zcr_speech]
        is_speech = sum(speech_indicators) >= 2
        
        return is_speech, volume

class FunASRStyleRecorder:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.vad = AdvancedVAD()
        self.is_recording = False
        self.frames = []
        self.stop_event = threading.Event()
        self.last_activity_time = 0
        self.ring_buffer = collections.deque(maxlen=int(RATE / CHUNK * RECORD_PADDING))
        
        # å…³é”®è¯æ£€æµ‹ç›¸å…³å˜é‡
        self.speech_start_time = None
        self.continuous_speech_frames = []
        self.is_speech_active = False
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir = "recordings"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"å·²åˆå§‹åŒ– FunASR-style VAD å½•éŸ³ç³»ç»Ÿ")
        print(f"ä½¿ç”¨é«˜çº§è¯­éŸ³æ£€æµ‹ç®—æ³• - éœ€è¦æŒç»­è¯­éŸ³ {MIN_SPEECH_DURATION}ç§’")
    
    def start_stream(self):
        """å¼€å§‹éŸ³é¢‘æµå¤„ç†"""
        print(f"æ­£åœ¨ç›‘å¬è¯­éŸ³æ´»åŠ¨ (æ¨¡æ‹Ÿå…³é”®è¯ '{KEYWORD}')")
        print("ä½¿ç”¨: éŸ³é‡ + èƒ½é‡ + è¿‡é›¶ç‡ ç»¼åˆæ£€æµ‹")
        
        stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK,
            stream_callback=self.audio_callback
        )
        
        try:
            while not self.stop_event.is_set():
                time.sleep(0.1)
                
                # å¦‚æœå½•éŸ³ä¸­ä½†æ£€æµ‹åˆ°é•¿æ—¶é—´é™éŸ³ï¼Œåœæ­¢å½•éŸ³
                if self.is_recording and (time.time() - self.last_activity_time) > SILENCE_DURATION:
                    print("æ£€æµ‹åˆ°æŒç»­é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                    self.stop_recording()
                    
        except KeyboardInterrupt:
            print("ç¨‹åºå·²åœæ­¢")
        finally:
            stream.stop_stream()
            stream.close()
            self.audio.terminate()
            if self.is_recording:
                self.stop_recording()
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é¢‘æµå›è°ƒå‡½æ•°"""
        data = np.frombuffer(in_data, dtype=np.int16).astype(np.float32)
        
        # ä½¿ç”¨é«˜çº§ VAD æ£€æµ‹
        is_speech, volume = self.vad.is_speech(data)
        is_strong_speech = volume > ACTIVITY_THRESHOLD
        
        # å§‹ç»ˆå°†æ•°æ®æ·»åŠ åˆ°ç¯å½¢ç¼“å†²åŒº
        self.ring_buffer.append(in_data)
        
        # å…³é”®è¯æ£€æµ‹é€»è¾‘ (åŸºäºæŒç»­è¯­éŸ³æ´»åŠ¨)
        if not self.is_recording:
            if is_strong_speech and not self.is_speech_active:
                # æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                self.is_speech_active = True
                self.speech_start_time = time.time()
                self.continuous_speech_frames = [in_data]
                print(f"é«˜çº§VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ï¼ŒéŸ³é‡: {volume:.0f}")
                
            elif is_speech and self.is_speech_active:
                # æŒç»­çš„è¯­éŸ³
                self.continuous_speech_frames.append(in_data)
                speech_duration = time.time() - self.speech_start_time
                
                # å¦‚æœè¯­éŸ³æŒç»­æ—¶é—´è¶…è¿‡é˜ˆå€¼ï¼Œè§†ä¸º"å…³é”®è¯"
                if speech_duration >= MIN_SPEECH_DURATION and not self.is_recording:
                    print(f"æ£€æµ‹åˆ°æŒç»­è¯­éŸ³ {speech_duration:.2f}ç§’ï¼Œè§¦å‘å½•éŸ³")
                    self.start_recording()
                    
            elif not is_speech and self.is_speech_active:
                # è¯­éŸ³ä¸­æ–­
                self.is_speech_active = False
                speech_duration = time.time() - self.speech_start_time
                if speech_duration < MIN_SPEECH_DURATION:
                    print(f"è¯­éŸ³å¤ªçŸ­ ({speech_duration:.2f}ç§’)ï¼Œå¿½ç•¥")
                self.continuous_speech_frames = []
        
        # å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œæ›´æ–°æ´»åŠ¨æ—¶é—´å’Œä¿å­˜å¸§
        if self.is_recording:
            if is_speech:
                self.last_activity_time = time.time()
            self.frames.append(in_data)
            
        return (in_data, pyaudio.paContinue)
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if not self.is_recording:
            print("ğŸ¤ å¼€å§‹å½•éŸ³...")
            self.is_recording = True
            self.frames = []
            # æ·»åŠ ä¹‹å‰çš„ç¼“å†²åŒºéŸ³é¢‘
            for frame in self.ring_buffer:
                self.frames.append(frame)
            self.last_activity_time = time.time()
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³å¹¶ä¿å­˜æ–‡ä»¶"""
        if self.is_recording:
            self.is_recording = False
            
            # ä¿å­˜å½•éŸ³æ–‡ä»¶
            if len(self.frames) > 0:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = os.path.join(self.output_dir, f"fanasr_recording_{timestamp}.wav")
                self.save_audio(filename)
                print(f"âœ… å½•éŸ³å·²ä¿å­˜åˆ°: {filename}")
                print("ğŸ”„ ç»§ç»­ç›‘å¬è¯­éŸ³...")
            
            self.frames = []
    
    def save_audio(self, filename):
        """ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶"""
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(self.frames))
            
        # æ˜¾ç¤ºå½•éŸ³æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(filename) / 1024  # KB
        duration = len(self.frames) * CHUNK / RATE
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} KB, æ—¶é•¿: {duration:.2f} ç§’")
    
    def stop(self):
        """åœæ­¢å½•éŸ³ç³»ç»Ÿ"""
        self.stop_event.set()
        if self.is_recording:
            self.stop_recording()

def main():
    print("=" * 60)
    print("ğŸ¯ FunASR-style é«˜çº§ VAD è¯­éŸ³æ¿€æ´»å½•éŸ³ç³»ç»Ÿ")
    print("=" * 60)
    print(f"ğŸ“‹ é…ç½®:")
    print(f"   - æœ€å°è¯­éŸ³æ—¶é•¿: {MIN_SPEECH_DURATION} ç§’")
    print(f"   - ä½¿ç”¨é«˜çº§æ£€æµ‹: éŸ³é‡ + èƒ½é‡ + è¿‡é›¶ç‡")
    print(f"   - é™éŸ³ç»ˆæ­¢æ—¶é—´: {SILENCE_DURATION} ç§’")
    print("ğŸ¤ å¯¹ç€éº¦å…‹é£è¯´è¯å¼€å§‹å½•éŸ³")
    print("â¹ï¸  æŒ‰ Ctrl+C é€€å‡ºç¨‹åº")
    print("-" * 60)
    
    recorder = FunASRStyleRecorder()
    
    try:
        recorder.start_stream()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºå·²åœæ­¢")
    finally:
        recorder.stop()

if __name__ == "__main__":
    main()
