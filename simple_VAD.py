#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç®€åŒ–ç‰ˆ VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ
å®ç°åŸºæœ¬çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹åŠŸèƒ½
"""

import os
import time
import wave
import numpy as np
import threading
from datetime import datetime
import colorama
from colorama import Fore, Style

# åˆå§‹åŒ– colorama
colorama.init()

try:
    import pyaudio
    print(f"{Fore.GREEN}âœ“ PyAudio æ¨¡å—å·²åŠ è½½{Style.RESET_ALL}")
except ImportError:
    print(f"{Fore.RED}âœ— PyAudio æœªå®‰è£…{Style.RESET_ALL}")
    exit(1)

# é…ç½®å‚æ•°
RATE = 16000
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1

# VAD å‚æ•°
ENERGY_THRESHOLD = 0.01
ZCR_THRESHOLD = 0.1
MIN_SPEECH_DURATION = 1.0
SILENCE_DURATION = 2.0

class SimpleVAD:
    """ç®€å•çš„ VAD å®ç°"""
    
    def __init__(self):
        self.energy_history = []
        self.background_energy = 0.001
        
    def calculate_energy(self, frame):
        """è®¡ç®—éŸ³é¢‘å¸§èƒ½é‡"""
        return np.mean(frame ** 2)
    
    def calculate_zcr(self, frame):
        """è®¡ç®—è¿‡é›¶ç‡"""
        return np.mean(0.5 * np.abs(np.diff(np.sign(frame))))
    
    def update_background(self, energy):
        """æ›´æ–°èƒŒæ™¯å™ªå£°ä¼°è®¡"""
        self.energy_history.append(energy)
        if len(self.energy_history) > 50:
            self.energy_history.pop(0)
        
        if len(self.energy_history) >= 10:
            self.background_energy = np.percentile(self.energy_history, 20)
    
    def is_speech(self, frame):
        """åˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³"""
        # å½’ä¸€åŒ–éŸ³é¢‘
        if len(frame) == 0:
            return False, {}
            
        frame = frame.astype(np.float32) / 32768.0
        
        # è®¡ç®—ç‰¹å¾
        energy = self.calculate_energy(frame)
        zcr = self.calculate_zcr(frame)
        
        # æ›´æ–°èƒŒæ™¯å™ªå£°
        self.update_background(energy)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        adaptive_threshold = max(self.background_energy * 5, ENERGY_THRESHOLD)
        
        # åˆ¤æ–­æ¡ä»¶
        energy_check = energy > adaptive_threshold
        zcr_check = zcr > ZCR_THRESHOLD
        
        features = {
            'energy': energy,
            'zcr': zcr,
            'threshold': adaptive_threshold,
            'background': self.background_energy
        }
        
        # è¯­éŸ³åˆ¤æ–­ï¼šèƒ½é‡è¶…è¿‡é˜ˆå€¼ä¸”è¿‡é›¶ç‡åˆç†
        is_speech = energy_check and zcr_check
        
        return is_speech, features

class VADRecorder:
    """VAD å½•éŸ³å™¨"""
    
    def __init__(self):
        print(f"\n{Fore.CYAN}{Style.BRIGHT}{'='*50}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{Style.BRIGHT}      VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹å½•éŸ³ç³»ç»Ÿ{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{Style.BRIGHT}{'='*50}{Style.RESET_ALL}\n")
        
        # åˆå§‹åŒ–éŸ³é¢‘
        self.audio = pyaudio.PyAudio()
        self.vad = SimpleVAD()
        
        # æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
        self.check_audio_devices()
        
        # å½•éŸ³çŠ¶æ€
        self.is_recording = False
        self.frames = []
        self.stop_flag = False
        
        # è¯­éŸ³çŠ¶æ€
        self.speech_active = False
        self.speech_start_time = None
        self.silence_start_time = None
        
        # è¾“å‡ºç›®å½•
        self.output_dir = "recordings"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"{Fore.GREEN}âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ{Style.RESET_ALL}\n")
    
    def check_audio_devices(self):
        """æ£€æŸ¥éŸ³é¢‘è®¾å¤‡"""
        device_count = self.audio.get_device_count()
        print(f"{Fore.BLUE}éŸ³é¢‘è®¾å¤‡åˆ—è¡¨:{Style.RESET_ALL}")
        
        input_devices = 0
        for i in range(device_count):
            info = self.audio.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                input_devices += 1
                print(f"  [{i}] {info['name']} (è¾“å…¥é€šé“: {info['maxInputChannels']})")
        
        if input_devices == 0:
            raise Exception("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡")
        
        print(f"{Fore.GREEN}âœ“ æ‰¾åˆ° {input_devices} ä¸ªè¾“å…¥è®¾å¤‡{Style.RESET_ALL}")
    
    def display_status(self, is_speech, features):
        """æ˜¾ç¤ºå®æ—¶çŠ¶æ€"""
        status_color = Fore.GREEN if is_speech else Fore.BLUE
        speech_indicator = "ğŸ¤ è¯­éŸ³" if is_speech else "ğŸ”‡ é™éŸ³"
        
        # æ¸…é™¤è¡Œå¹¶æ˜¾ç¤ºçŠ¶æ€
        print(f"\r{status_color}{speech_indicator}{Style.RESET_ALL} | "
              f"èƒ½é‡: {features['energy']:.4f} | "
              f"è¿‡é›¶ç‡: {features['zcr']:.3f} | "
              f"é˜ˆå€¼: {features['threshold']:.4f} | "
              f"èƒŒæ™¯: {features['background']:.4f}", end='')
    
    def start_stream(self):
        """å¼€å§‹éŸ³é¢‘æµ"""
        print(f"{Fore.YELLOW}å¼€å§‹è¯­éŸ³ç›‘å¬... æŒ‰ Ctrl+C åœæ­¢{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*50}{Style.RESET_ALL}")
        
        try:
            stream = self.audio.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK
            )
            
            stream.start_stream()
            
            while not self.stop_flag:
                if stream.is_active():
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    self.process_audio(data)
                else:
                    time.sleep(0.01)
                    
        except Exception as e:
            print(f"\n{Fore.RED}éŸ³é¢‘æµé”™è¯¯: {e}{Style.RESET_ALL}")
        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}ç”¨æˆ·åœæ­¢ç¨‹åº{Style.RESET_ALL}")
        finally:
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass
            self.audio.terminate()
            
            if self.is_recording:
                self.stop_recording()
    
    def process_audio(self, data):
        """å¤„ç†éŸ³é¢‘æ•°æ®"""
        # è½¬æ¢ä¸º numpy æ•°ç»„
        audio_array = np.frombuffer(data, dtype=np.int16)
        
        # VAD æ£€æµ‹
        is_speech, features = self.vad.is_speech(audio_array)
        
        # æ˜¾ç¤ºå®æ—¶çŠ¶æ€
        self.display_status(is_speech, features)
        
        current_time = time.time()
        
        # è¯­éŸ³çŠ¶æ€æœº
        if is_speech:
            if not self.speech_active:
                # è¯­éŸ³å¼€å§‹
                self.speech_active = True
                self.speech_start_time = current_time
                self.silence_start_time = None
                print(f"\n{Fore.YELLOW}ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹{Style.RESET_ALL}")
        else:
            if self.speech_active:
                if self.silence_start_time is None:
                    self.silence_start_time = current_time
                
                # æ£€æŸ¥é™éŸ³æ—¶é•¿
                silence_duration = current_time - self.silence_start_time
                if silence_duration >= SILENCE_DURATION:
                    # è¯­éŸ³ç»“æŸ
                    speech_duration = current_time - self.speech_start_time
                    print(f"\n{Fore.CYAN}ğŸ”‡ è¯­éŸ³ç»“æŸï¼ŒæŒç»­ {speech_duration:.2f} ç§’{Style.RESET_ALL}")
                    
                    if speech_duration >= MIN_SPEECH_DURATION:
                        if not self.is_recording:
                            print(f"{Fore.GREEN}âœ“ å¼€å§‹å½•éŸ³ (è¯­éŸ³æ—¶é•¿: {speech_duration:.2f}s){Style.RESET_ALL}")
                            self.start_recording()
                        else:
                            print(f"{Fore.CYAN}âœ“ åœæ­¢å½•éŸ³{Style.RESET_ALL}")
                            self.stop_recording()
                    else:
                        print(f"{Fore.RED}âœ— è¯­éŸ³å¤ªçŸ­ï¼Œå¿½ç•¥ ({speech_duration:.2f}s < {MIN_SPEECH_DURATION}s){Style.RESET_ALL}")
                    
                    self.speech_active = False
                    self.speech_start_time = None
                    self.silence_start_time = None
        
        # å½•éŸ³ä¸­åˆ™ä¿å­˜æ•°æ®
        if self.is_recording:
            self.frames.append(data)
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        self.is_recording = True
        self.frames = []
        print(f"{Fore.GREEN}ğŸ”´ å¼€å§‹å½•éŸ³...{Style.RESET_ALL}")
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if self.is_recording and len(self.frames) > 0:
            self.is_recording = False
            
            # ä¿å­˜æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.output_dir, f"vad_rec_{timestamp}.wav")
            
            with wave.open(filename, 'wb') as wf:
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(self.audio.get_sample_size(FORMAT))
                wf.setframerate(RATE)
                wf.writeframes(b''.join(self.frames))
            
            # æ˜¾ç¤ºä¿¡æ¯
            duration = len(self.frames) * CHUNK / RATE
            file_size = os.path.getsize(filename) / 1024
            print(f"{Fore.CYAN}ğŸ“ å½•éŸ³ä¿å­˜: {filename}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ğŸ“Š æ—¶é•¿: {duration:.2f}s, å¤§å°: {file_size:.1f}KB{Style.RESET_ALL}")
            
            self.frames = []
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.stop_flag = True

def main():
    """ä¸»å‡½æ•°"""
    print(f"{Fore.CYAN}{Style.BRIGHT}ç®€åŒ–ç‰ˆ VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}é…ç½®: æœ€å°è¯­éŸ³ {MIN_SPEECH_DURATION}s, é™éŸ³è¶…æ—¶ {SILENCE_DURATION}s{Style.RESET_ALL}")
    
    try:
        recorder = VADRecorder()
        recorder.start_stream()
    except Exception as e:
        print(f"\n{Fore.RED}ç³»ç»Ÿé”™è¯¯: {e}{Style.RESET_ALL}")

if __name__ == "__main__":
    main()
